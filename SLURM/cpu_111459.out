Logging to ./logs/2019-05-16_21-03-21
env_type: envs
pygame 1.9.6
Hello from the pygame community. https://www.pygame.org/contribute.html
Game images are going to be loaded from: /hb/home/mamoghad/Scripts/gym-deepcars-baselines/image/
Training deepq on envs:DeepCars-v0 with arguments 
{'network': 'deep_mlp'}
----------------------------------
| % time spent exploring  | 98   |
| episodes                | 100  |
| mean 100 episode reward | 9.8  |
| steps                   | 1167 |
----------------------------------
----------------------------------
| % time spent exploring  | 97   |
| episodes                | 200  |
| mean 100 episode reward | 9.6  |
| steps                   | 2328 |
----------------------------------
----------------------------------
| % time spent exploring  | 96   |
| episodes                | 300  |
| mean 100 episode reward | 10.9 |
| steps                   | 3621 |
----------------------------------
----------------------------------
| % time spent exploring  | 95   |
| episodes                | 400  |
| mean 100 episode reward | 10.7 |
| steps                   | 4888 |
----------------------------------
----------------------------------
| % time spent exploring  | 93   |
| episodes                | 500  |
| mean 100 episode reward | 10.4 |
| steps                   | 6129 |
----------------------------------
----------------------------------
| % time spent exploring  | 92   |
| episodes                | 600  |
| mean 100 episode reward | 11.0 |
| steps                   | 7425 |
----------------------------------
----------------------------------
| % time spent exploring  | 91   |
| episodes                | 700  |
| mean 100 episode reward | 10.9 |
| steps                   | 8717 |
----------------------------------
----------------------------------
| % time spent exploring  | 90   |
| episodes                | 800  |
| mean 100 episode reward | 10.5 |
| steps                   | 9963 |
----------------------------------
Saving model due to mean reward increase: None -> 10.5
-----------------------------------
| % time spent exploring  | 88    |
| episodes                | 900   |
| mean 100 episode reward | 11.0  |
| steps                   | 11260 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 87    |
| episodes                | 1000  |
| mean 100 episode reward | 10.7  |
| steps                   | 12532 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 86    |
| episodes                | 1100  |
| mean 100 episode reward | 10.4  |
| steps                   | 13767 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 85    |
| episodes                | 1200  |
| mean 100 episode reward | 10.4  |
| steps                   | 15004 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 84    |
| episodes                | 1300  |
| mean 100 episode reward | 11.0  |
| steps                   | 16309 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 82    |
| episodes                | 1400  |
| mean 100 episode reward | 12.1  |
| steps                   | 17722 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 81    |
| episodes                | 1500  |
| mean 100 episode reward | 10.6  |
| steps                   | 18984 |
-----------------------------------
Saving model due to mean reward increase: 10.5 -> 11.0
-----------------------------------
| % time spent exploring  | 80    |
| episodes                | 1600  |
| mean 100 episode reward | 11.1  |
| steps                   | 20294 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 78    |
| episodes                | 1700  |
| mean 100 episode reward | 11.3  |
| steps                   | 21621 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 77    |
| episodes                | 1800  |
| mean 100 episode reward | 12.5  |
| steps                   | 23068 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 76    |
| episodes                | 1900  |
| mean 100 episode reward | 11.9  |
| steps                   | 24458 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 74    |
| episodes                | 2000  |
| mean 100 episode reward | 11.8  |
| steps                   | 25841 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 73    |
| episodes                | 2100  |
| mean 100 episode reward | 13.1  |
| steps                   | 27349 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 71    |
| episodes                | 2200  |
| mean 100 episode reward | 11.5  |
| steps                   | 28701 |
-----------------------------------
Saving model due to mean reward increase: 11.0 -> 11.899999618530273
-----------------------------------
| % time spent exploring  | 70    |
| episodes                | 2300  |
| mean 100 episode reward | 12.4  |
| steps                   | 30142 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 69    |
| episodes                | 2400  |
| mean 100 episode reward | 12.4  |
| steps                   | 31579 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 67    |
| episodes                | 2500  |
| mean 100 episode reward | 12.8  |
| steps                   | 33062 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 66    |
| episodes                | 2600  |
| mean 100 episode reward | 13.5  |
| steps                   | 34610 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 64    |
| episodes                | 2700  |
| mean 100 episode reward | 13.3  |
| steps                   | 36139 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 63    |
| episodes                | 2800  |
| mean 100 episode reward | 13.1  |
| steps                   | 37651 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 61    |
| episodes                | 2900  |
| mean 100 episode reward | 14.2  |
| steps                   | 39271 |
-----------------------------------
Saving model due to mean reward increase: 11.899999618530273 -> 13.0
-----------------------------------
| % time spent exploring  | 60    |
| episodes                | 3000  |
| mean 100 episode reward | 12.9  |
| steps                   | 40759 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 58    |
| episodes                | 3100  |
| mean 100 episode reward | 13.5  |
| steps                   | 42313 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 57    |
| episodes                | 3200  |
| mean 100 episode reward | 12.8  |
| steps                   | 43798 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 55    |
| episodes                | 3300  |
| mean 100 episode reward | 15.1  |
| steps                   | 45511 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 53    |
| episodes                | 3400  |
| mean 100 episode reward | 14.0  |
| steps                   | 47112 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 52    |
| episodes                | 3500  |
| mean 100 episode reward | 14.3  |
| steps                   | 48738 |
-----------------------------------
Saving model due to mean reward increase: 13.0 -> 13.899999618530273
-----------------------------------
| % time spent exploring  | 50    |
| episodes                | 3600  |
| mean 100 episode reward | 13.6  |
| steps                   | 50296 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 49    |
| episodes                | 3700  |
| mean 100 episode reward | 14.1  |
| steps                   | 51909 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 47    |
| episodes                | 3800  |
| mean 100 episode reward | 14.9  |
| steps                   | 53602 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 45    |
| episodes                | 3900  |
| mean 100 episode reward | 17.1  |
| steps                   | 55511 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 43    |
| episodes                | 4000  |
| mean 100 episode reward | 16.3  |
| steps                   | 57345 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 41    |
| episodes                | 4100  |
| mean 100 episode reward | 20.4  |
| steps                   | 59582 |
-----------------------------------
Saving model due to mean reward increase: 13.899999618530273 -> 20.799999237060547
-----------------------------------
| % time spent exploring  | 39    |
| episodes                | 4200  |
| mean 100 episode reward | 16.6  |
| steps                   | 61447 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 38    |
| episodes                | 4300  |
| mean 100 episode reward | 15.7  |
| steps                   | 63213 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 35    |
| episodes                | 4400  |
| mean 100 episode reward | 20.2  |
| steps                   | 65433 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 33    |
| episodes                | 4500  |
| mean 100 episode reward | 18.6  |
| steps                   | 67494 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 31    |
| episodes                | 4600  |
| mean 100 episode reward | 20.2  |
| steps                   | 69713 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 29    |
| episodes                | 4700  |
| mean 100 episode reward | 21.3  |
| steps                   | 72046 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 26    |
| episodes                | 4800  |
| mean 100 episode reward | 23.6  |
| steps                   | 74607 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 23    |
| episodes                | 4900  |
| mean 100 episode reward | 28.7  |
| steps                   | 77674 |
-----------------------------------
Saving model due to mean reward increase: 20.799999237060547 -> 25.700000762939453
-----------------------------------
| % time spent exploring  | 21    |
| episodes                | 5000  |
| mean 100 episode reward | 26.7  |
| steps                   | 80546 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 17    |
| episodes                | 5100  |
| mean 100 episode reward | 30.0  |
| steps                   | 83747 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 13    |
| episodes                | 5200  |
| mean 100 episode reward | 38.1  |
| steps                   | 87756 |
-----------------------------------
Saving model due to mean reward increase: 25.700000762939453 -> 43.099998474121094
-----------------------------------
| % time spent exploring  | 8     |
| episodes                | 5300  |
| mean 100 episode reward | 55.3  |
| steps                   | 93484 |
-----------------------------------
Saving model due to mean reward increase: 43.099998474121094 -> 82.19999694824219
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 5400   |
| mean 100 episode reward | 147.4  |
| steps                   | 108423 |
------------------------------------
Saving model due to mean reward increase: 82.19999694824219 -> 155.0
Saving model due to mean reward increase: 155.0 -> 226.5
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 5500   |
| mean 100 episode reward | 218.7  |
| steps                   | 130490 |
------------------------------------
Saving model due to mean reward increase: 226.5 -> 232.10000610351562
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 5600   |
| mean 100 episode reward | 255.4  |
| steps                   | 156229 |
------------------------------------
Saving model due to mean reward increase: 232.10000610351562 -> 257.5
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 5700   |
| mean 100 episode reward | 256.0  |
| steps                   | 182025 |
------------------------------------
Saving model due to mean reward increase: 257.5 -> 269.79998779296875
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 5800   |
| mean 100 episode reward | 229.4  |
| steps                   | 205169 |
------------------------------------
Saving model due to mean reward increase: 269.79998779296875 -> 270.29998779296875
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 5900   |
| mean 100 episode reward | 269.1  |
| steps                   | 232280 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 6000   |
| mean 100 episode reward | 235.0  |
| steps                   | 255980 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 6100   |
| mean 100 episode reward | 243.3  |
| steps                   | 280509 |
------------------------------------
Saving model due to mean reward increase: 270.29998779296875 -> 274.29998779296875
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 6200   |
| mean 100 episode reward | 266.6  |
| steps                   | 307372 |
------------------------------------
Saving model due to mean reward increase: 274.29998779296875 -> 288.3999938964844
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 6300   |
| mean 100 episode reward | 271.5  |
| steps                   | 334721 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 6400   |
| mean 100 episode reward | 259.6  |
| steps                   | 360881 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 6500   |
| mean 100 episode reward | 229.9  |
| steps                   | 384073 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 6600   |
| mean 100 episode reward | 239.9  |
| steps                   | 408264 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 6700   |
| mean 100 episode reward | 269.5  |
| steps                   | 435412 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 6800   |
| mean 100 episode reward | 239.2  |
| steps                   | 459534 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 6900   |
| mean 100 episode reward | 240.8  |
| steps                   | 483817 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 7000   |
| mean 100 episode reward | 270.4  |
| steps                   | 511060 |
------------------------------------
Saving model due to mean reward increase: 288.3999938964844 -> 290.70001220703125
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 7100   |
| mean 100 episode reward | 260.0  |
| steps                   | 537262 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 7200   |
| mean 100 episode reward | 267.8  |
| steps                   | 564241 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 7300   |
| mean 100 episode reward | 250.6  |
| steps                   | 589496 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 7400   |
| mean 100 episode reward | 280.0  |
| steps                   | 617696 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 7500   |
| mean 100 episode reward | 246.1  |
| steps                   | 642509 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 7600   |
| mean 100 episode reward | 223.0  |
| steps                   | 665005 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 7700   |
| mean 100 episode reward | 251.4  |
| steps                   | 690343 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 7800   |
| mean 100 episode reward | 261.0  |
| steps                   | 716640 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 7900   |
| mean 100 episode reward | 241.3  |
| steps                   | 740974 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 8000   |
| mean 100 episode reward | 239.8  |
| steps                   | 765152 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 8100   |
| mean 100 episode reward | 272.0  |
| steps                   | 792550 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 8200   |
| mean 100 episode reward | 257.0  |
| steps                   | 818446 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 8300   |
| mean 100 episode reward | 228.8  |
| steps                   | 841521 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 8400   |
| mean 100 episode reward | 249.6  |
| steps                   | 866676 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 8500   |
| mean 100 episode reward | 289.2  |
| steps                   | 895797 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 8600   |
| mean 100 episode reward | 279.5  |
| steps                   | 923948 |
------------------------------------
Saving model due to mean reward increase: 290.70001220703125 -> 296.70001220703125
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 8700   |
| mean 100 episode reward | 275.7  |
| steps                   | 951719 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 8800   |
| mean 100 episode reward | 250.4  |
| steps                   | 976963 |
------------------------------------
Restored model with mean reward: 296.70001220703125
Saving model to log directory...
model saved!
------------------Inpute arguments------------------
Namespace(alg='deepq', env='DeepCars-v0', env_type=None, extra_import=None, gamestate=None, network='deep_mlp', num_env=None, num_timesteps=1000000.0, play=False, reward_scale=1.0, save_path=None, save_video_interval=0, save_video_length=200, seed=None)
{}
----------------------------------------------------
