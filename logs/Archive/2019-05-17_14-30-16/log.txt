Logging to ./logs/2019-05-17_14-30-16
----------------------------------
| % time spent exploring  | 97   |
| episodes                | 100  |
| mean 100 episode reward | 9.6  |
| steps                   | 1152 |
----------------------------------
----------------------------------
| % time spent exploring  | 95   |
| episodes                | 200  |
| mean 100 episode reward | 9.7  |
| steps                   | 2326 |
----------------------------------
----------------------------------
| % time spent exploring  | 92   |
| episodes                | 300  |
| mean 100 episode reward | 10.6 |
| steps                   | 3586 |
----------------------------------
----------------------------------
| % time spent exploring  | 90   |
| episodes                | 400  |
| mean 100 episode reward | 10.2 |
| steps                   | 4811 |
----------------------------------
----------------------------------
| % time spent exploring  | 88   |
| episodes                | 500  |
| mean 100 episode reward | 10.0 |
| steps                   | 6014 |
----------------------------------
----------------------------------
| % time spent exploring  | 85   |
| episodes                | 600  |
| mean 100 episode reward | 11.1 |
| steps                   | 7327 |
----------------------------------
----------------------------------
| % time spent exploring  | 83   |
| episodes                | 700  |
| mean 100 episode reward | 10.9 |
| steps                   | 8618 |
----------------------------------
----------------------------------
| % time spent exploring  | 80   |
| episodes                | 800  |
| mean 100 episode reward | 11.5 |
| steps                   | 9970 |
----------------------------------
Saving model due to mean reward increase: None -> 11.399999618530273
-----------------------------------
| % time spent exploring  | 77    |
| episodes                | 900   |
| mean 100 episode reward | 11.2  |
| steps                   | 11287 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 75    |
| episodes                | 1000  |
| mean 100 episode reward | 11.5  |
| steps                   | 12634 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 72    |
| episodes                | 1100  |
| mean 100 episode reward | 13.1  |
| steps                   | 14142 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 69    |
| episodes                | 1200  |
| mean 100 episode reward | 11.7  |
| steps                   | 15512 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 66    |
| episodes                | 1300  |
| mean 100 episode reward | 11.6  |
| steps                   | 16868 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 63    |
| episodes                | 1400  |
| mean 100 episode reward | 13.1  |
| steps                   | 18374 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 60    |
| episodes                | 1500  |
| mean 100 episode reward | 13.4  |
| steps                   | 19912 |
-----------------------------------
Saving model due to mean reward increase: 11.399999618530273 -> 13.5
-----------------------------------
| % time spent exploring  | 57    |
| episodes                | 1600  |
| mean 100 episode reward | 14.1  |
| steps                   | 21525 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 54    |
| episodes                | 1700  |
| mean 100 episode reward | 12.8  |
| steps                   | 23000 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 51    |
| episodes                | 1800  |
| mean 100 episode reward | 13.5  |
| steps                   | 24546 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 48    |
| episodes                | 1900  |
| mean 100 episode reward | 16.7  |
| steps                   | 26412 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 44    |
| episodes                | 2000  |
| mean 100 episode reward | 15.4  |
| steps                   | 28152 |
-----------------------------------
Saving model due to mean reward increase: 13.5 -> 17.399999618530273
-----------------------------------
| % time spent exploring  | 40    |
| episodes                | 2100  |
| mean 100 episode reward | 17.7  |
| steps                   | 30124 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 37    |
| episodes                | 2200  |
| mean 100 episode reward | 18.0  |
| steps                   | 32122 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 32    |
| episodes                | 2300  |
| mean 100 episode reward | 20.3  |
| steps                   | 34353 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 27    |
| episodes                | 2400  |
| mean 100 episode reward | 22.3  |
| steps                   | 36782 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 22    |
| episodes                | 2500  |
| mean 100 episode reward | 26.7  |
| steps                   | 39650 |
-----------------------------------
Saving model due to mean reward increase: 17.399999618530273 -> 27.399999618530273
-----------------------------------
| % time spent exploring  | 16    |
| episodes                | 2600  |
| mean 100 episode reward | 29.2  |
| steps                   | 42768 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 3     |
| episodes                | 2700  |
| mean 100 episode reward | 63.8  |
| steps                   | 49351 |
-----------------------------------
Saving model due to mean reward increase: 27.399999618530273 -> 67.80000305175781
Saving model due to mean reward increase: 67.80000305175781 -> 144.8000030517578
Saving model due to mean reward increase: 144.8000030517578 -> 208.3000030517578
-----------------------------------
| % time spent exploring  | 2     |
| episodes                | 2800  |
| mean 100 episode reward | 216.4 |
| steps                   | 71189 |
-----------------------------------
Saving model due to mean reward increase: 208.3000030517578 -> 236.10000610351562
Saving model due to mean reward increase: 236.10000610351562 -> 251.89999389648438
Saving model due to mean reward increase: 251.89999389648438 -> 298.20001220703125
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 2900   |
| mean 100 episode reward | 313.8  |
| steps                   | 102767 |
------------------------------------
Saving model due to mean reward increase: 298.20001220703125 -> 316.79998779296875
Saving model due to mean reward increase: 316.79998779296875 -> 331.5
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 3000   |
| mean 100 episode reward | 296.5  |
| steps                   | 132614 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 3100   |
| mean 100 episode reward | 304.2  |
| steps                   | 163234 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 3200   |
| mean 100 episode reward | 243.4  |
| steps                   | 187776 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 3300   |
| mean 100 episode reward | 260.8  |
| steps                   | 214054 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 3400   |
| mean 100 episode reward | 229.4  |
| steps                   | 237190 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 3500   |
| mean 100 episode reward | 331.9  |
| steps                   | 270580 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 3600   |
| mean 100 episode reward | 224.8  |
| steps                   | 293263 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 3700   |
| mean 100 episode reward | 229.2  |
| steps                   | 316386 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 3800   |
| mean 100 episode reward | 212.1  |
| steps                   | 337799 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 3900   |
| mean 100 episode reward | 238.4  |
| steps                   | 361837 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 4000   |
| mean 100 episode reward | 252.4  |
| steps                   | 387278 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 4100   |
| mean 100 episode reward | 273.1  |
| steps                   | 414791 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 4200   |
| mean 100 episode reward | 251.8  |
| steps                   | 440176 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 4300   |
| mean 100 episode reward | 274.2  |
| steps                   | 467791 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 4400   |
| mean 100 episode reward | 218.0  |
| steps                   | 489795 |
------------------------------------
Restored model with mean reward: 331.5
------------------Inpute arguments------------------
Namespace(alg='deepq', env='DeepCars-v0', env_type=None, extra_import=None, gamestate=None, network='shallow_mlp', num_env=None, num_timesteps=500000.0, play=False, reward_scale=1.0, save_path=None, save_video_interval=0, save_video_length=200, seed=None)
{}
----------------------------------------------------
