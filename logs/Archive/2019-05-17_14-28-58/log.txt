Logging to ./logs/2019-05-17_14-28-58
----------------------------------
| % time spent exploring  | 97   |
| episodes                | 100  |
| mean 100 episode reward | 10.2 |
| steps                   | 1211 |
----------------------------------
----------------------------------
| % time spent exploring  | 95   |
| episodes                | 200  |
| mean 100 episode reward | 10.5 |
| steps                   | 2460 |
----------------------------------
----------------------------------
| % time spent exploring  | 92   |
| episodes                | 300  |
| mean 100 episode reward | 10.5 |
| steps                   | 3712 |
----------------------------------
----------------------------------
| % time spent exploring  | 90   |
| episodes                | 400  |
| mean 100 episode reward | 10.6 |
| steps                   | 4973 |
----------------------------------
----------------------------------
| % time spent exploring  | 87   |
| episodes                | 500  |
| mean 100 episode reward | 10.4 |
| steps                   | 6215 |
----------------------------------
----------------------------------
| % time spent exploring  | 85   |
| episodes                | 600  |
| mean 100 episode reward | 10.8 |
| steps                   | 7497 |
----------------------------------
----------------------------------
| % time spent exploring  | 82   |
| episodes                | 700  |
| mean 100 episode reward | 10.5 |
| steps                   | 8751 |
----------------------------------
Saving model due to mean reward increase: None -> 10.800000190734863
-----------------------------------
| % time spent exploring  | 80    |
| episodes                | 800   |
| mean 100 episode reward | 10.8  |
| steps                   | 10027 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 77    |
| episodes                | 900   |
| mean 100 episode reward | 10.9  |
| steps                   | 11317 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 75    |
| episodes                | 1000  |
| mean 100 episode reward | 11.6  |
| steps                   | 12672 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 72    |
| episodes                | 1100  |
| mean 100 episode reward | 11.3  |
| steps                   | 14006 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 69    |
| episodes                | 1200  |
| mean 100 episode reward | 12.5  |
| steps                   | 15455 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 66    |
| episodes                | 1300  |
| mean 100 episode reward | 12.5  |
| steps                   | 16902 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 63    |
| episodes                | 1400  |
| mean 100 episode reward | 13.6  |
| steps                   | 18459 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 60    |
| episodes                | 1500  |
| mean 100 episode reward | 12.8  |
| steps                   | 19940 |
-----------------------------------
Saving model due to mean reward increase: 10.800000190734863 -> 12.600000381469727
-----------------------------------
| % time spent exploring  | 57    |
| episodes                | 1600  |
| mean 100 episode reward | 14.4  |
| steps                   | 21576 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 54    |
| episodes                | 1700  |
| mean 100 episode reward | 13.6  |
| steps                   | 23138 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 51    |
| episodes                | 1800  |
| mean 100 episode reward | 15.6  |
| steps                   | 24893 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 47    |
| episodes                | 1900  |
| mean 100 episode reward | 14.5  |
| steps                   | 26539 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 44    |
| episodes                | 2000  |
| mean 100 episode reward | 13.7  |
| steps                   | 28112 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 41    |
| episodes                | 2100  |
| mean 100 episode reward | 15.9  |
| steps                   | 29899 |
-----------------------------------
Saving model due to mean reward increase: 12.600000381469727 -> 15.899999618530273
-----------------------------------
| % time spent exploring  | 37    |
| episodes                | 2200  |
| mean 100 episode reward | 16.0  |
| steps                   | 31702 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 33    |
| episodes                | 2300  |
| mean 100 episode reward | 19.1  |
| steps                   | 33813 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 28    |
| episodes                | 2400  |
| mean 100 episode reward | 22.2  |
| steps                   | 36236 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 24    |
| episodes                | 2500  |
| mean 100 episode reward | 23.0  |
| steps                   | 38733 |
-----------------------------------
Saving model due to mean reward increase: 15.899999618530273 -> 23.600000381469727
-----------------------------------
| % time spent exploring  | 18    |
| episodes                | 2600  |
| mean 100 episode reward | 25.8  |
| steps                   | 41516 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 9     |
| episodes                | 2700  |
| mean 100 episode reward | 43.4  |
| steps                   | 46054 |
-----------------------------------
Saving model due to mean reward increase: 23.600000381469727 -> 57.5
Saving model due to mean reward increase: 57.5 -> 141.60000610351562
-----------------------------------
| % time spent exploring  | 2     |
| episodes                | 2800  |
| mean 100 episode reward | 151.0 |
| steps                   | 61356 |
-----------------------------------
Saving model due to mean reward increase: 141.60000610351562 -> 204.60000610351562
Saving model due to mean reward increase: 204.60000610351562 -> 209.0
-----------------------------------
| % time spent exploring  | 2     |
| episodes                | 2900  |
| mean 100 episode reward | 229.7 |
| steps                   | 84524 |
-----------------------------------
Saving model due to mean reward increase: 209.0 -> 253.89999389648438
Saving model due to mean reward increase: 253.89999389648438 -> 260.6000061035156
Saving model due to mean reward increase: 260.6000061035156 -> 265.3999938964844
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 3000   |
| mean 100 episode reward | 270.2  |
| steps                   | 111749 |
------------------------------------
Saving model due to mean reward increase: 265.3999938964844 -> 271.8999938964844
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 3100   |
| mean 100 episode reward | 243.6  |
| steps                   | 136307 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 3200   |
| mean 100 episode reward | 237.6  |
| steps                   | 160266 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 3300   |
| mean 100 episode reward | 257.0  |
| steps                   | 186166 |
------------------------------------
Saving model due to mean reward increase: 271.8999938964844 -> 272.79998779296875
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 3400   |
| mean 100 episode reward | 236.9  |
| steps                   | 210054 |
------------------------------------
Saving model due to mean reward increase: 272.79998779296875 -> 273.79998779296875
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 3500   |
| mean 100 episode reward | 283.8  |
| steps                   | 238638 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 3600   |
| mean 100 episode reward | 244.5  |
| steps                   | 263284 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 3700   |
| mean 100 episode reward | 249.7  |
| steps                   | 288453 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 3800   |
| mean 100 episode reward | 230.4  |
| steps                   | 311690 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 3900   |
| mean 100 episode reward | 246.6  |
| steps                   | 336547 |
------------------------------------
Saving model due to mean reward increase: 273.79998779296875 -> 277.70001220703125
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 4000   |
| mean 100 episode reward | 284.8  |
| steps                   | 365225 |
------------------------------------
Saving model due to mean reward increase: 277.70001220703125 -> 283.20001220703125
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 4100   |
| mean 100 episode reward | 289.5  |
| steps                   | 394374 |
------------------------------------
Saving model due to mean reward increase: 283.20001220703125 -> 294.70001220703125
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 4200   |
| mean 100 episode reward | 242.9  |
| steps                   | 418861 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 4300   |
| mean 100 episode reward | 235.0  |
| steps                   | 442563 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 4400   |
| mean 100 episode reward | 222.6  |
| steps                   | 465020 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 4500   |
| mean 100 episode reward | 250.2  |
| steps                   | 490241 |
------------------------------------
Restored model with mean reward: 294.70001220703125
------------------Inpute arguments------------------
Namespace(alg='deepq', env='DeepCars-v0', env_type=None, extra_import=None, gamestate=None, network='deep_mlp', num_env=None, num_timesteps=500000.0, play=False, reward_scale=1.0, save_path=None, save_video_interval=0, save_video_length=200, seed=None)
{}
----------------------------------------------------
