Logging to ./logs/2019-05-16_19-38-09
----------------------------------
| % time spent exploring  | 97   |
| episodes                | 100  |
| mean 100 episode reward | 10.3 |
| steps                   | 1215 |
----------------------------------
----------------------------------
| % time spent exploring  | 95   |
| episodes                | 200  |
| mean 100 episode reward | 9.7  |
| steps                   | 2384 |
----------------------------------
----------------------------------
| % time spent exploring  | 93   |
| episodes                | 300  |
| mean 100 episode reward | 9.6  |
| steps                   | 3544 |
----------------------------------
----------------------------------
| % time spent exploring  | 90   |
| episodes                | 400  |
| mean 100 episode reward | 10.7 |
| steps                   | 4815 |
----------------------------------
----------------------------------
| % time spent exploring  | 88   |
| episodes                | 500  |
| mean 100 episode reward | 10.4 |
| steps                   | 6057 |
----------------------------------
----------------------------------
| % time spent exploring  | 85   |
| episodes                | 600  |
| mean 100 episode reward | 11.5 |
| steps                   | 7406 |
----------------------------------
----------------------------------
| % time spent exploring  | 82   |
| episodes                | 700  |
| mean 100 episode reward | 11.9 |
| steps                   | 8792 |
----------------------------------
----------------------------------
| % time spent exploring  | 80   |
| episodes                | 800  |
| mean 100 episode reward | 9.9  |
| steps                   | 9986 |
----------------------------------
Saving model due to mean reward increase: None -> 9.899999618530273
-----------------------------------
| % time spent exploring  | 77    |
| episodes                | 900   |
| mean 100 episode reward | 12.3  |
| steps                   | 11414 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 74    |
| episodes                | 1000  |
| mean 100 episode reward | 11.8  |
| steps                   | 12797 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 72    |
| episodes                | 1100  |
| mean 100 episode reward | 11.5  |
| steps                   | 14147 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 69    |
| episodes                | 1200  |
| mean 100 episode reward | 12.6  |
| steps                   | 15607 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 66    |
| episodes                | 1300  |
| mean 100 episode reward | 13.2  |
| steps                   | 17123 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 63    |
| episodes                | 1400  |
| mean 100 episode reward | 13.4  |
| steps                   | 18658 |
-----------------------------------
Saving model due to mean reward increase: 9.899999618530273 -> 12.800000190734863
-----------------------------------
| % time spent exploring  | 60    |
| episodes                | 1500  |
| mean 100 episode reward | 13.0  |
| steps                   | 20159 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 57    |
| episodes                | 1600  |
| mean 100 episode reward | 14.5  |
| steps                   | 21809 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 53    |
| episodes                | 1700  |
| mean 100 episode reward | 14.9  |
| steps                   | 23501 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 50    |
| episodes                | 1800  |
| mean 100 episode reward | 15.8  |
| steps                   | 25286 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 46    |
| episodes                | 1900  |
| mean 100 episode reward | 16.3  |
| steps                   | 27116 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 43    |
| episodes                | 2000  |
| mean 100 episode reward | 14.5  |
| steps                   | 28766 |
-----------------------------------
Saving model due to mean reward increase: 12.800000190734863 -> 17.0
-----------------------------------
| % time spent exploring  | 39    |
| episodes                | 2100  |
| mean 100 episode reward | 17.1  |
| steps                   | 30676 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 35    |
| episodes                | 2200  |
| mean 100 episode reward | 18.4  |
| steps                   | 32719 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 31    |
| episodes                | 2300  |
| mean 100 episode reward | 19.7  |
| steps                   | 34891 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 27    |
| episodes                | 2400  |
| mean 100 episode reward | 21.5  |
| steps                   | 37243 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 22    |
| episodes                | 2500  |
| mean 100 episode reward | 23.4  |
| steps                   | 39788 |
-----------------------------------
Saving model due to mean reward increase: 17.0 -> 23.0
-----------------------------------
| % time spent exploring  | 14    |
| episodes                | 2600  |
| mean 100 episode reward | 35.1  |
| steps                   | 43494 |
-----------------------------------
-----------------------------------
| % time spent exploring  | 2     |
| episodes                | 2700  |
| mean 100 episode reward | 58.5  |
| steps                   | 49540 |
-----------------------------------
Saving model due to mean reward increase: 23.0 -> 58.5
Saving model due to mean reward increase: 58.5 -> 146.39999389648438
Saving model due to mean reward increase: 146.39999389648438 -> 223.39999389648438
-----------------------------------
| % time spent exploring  | 2     |
| episodes                | 2800  |
| mean 100 episode reward | 273.6 |
| steps                   | 77097 |
-----------------------------------
Saving model due to mean reward increase: 223.39999389648438 -> 276.79998779296875
Saving model due to mean reward increase: 276.79998779296875 -> 282.8999938964844
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 2900   |
| mean 100 episode reward | 241.2  |
| steps                   | 101422 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 3000   |
| mean 100 episode reward | 215.5  |
| steps                   | 123168 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 3100   |
| mean 100 episode reward | 290.7  |
| steps                   | 152435 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 3200   |
| mean 100 episode reward | 257.9  |
| steps                   | 178427 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 3300   |
| mean 100 episode reward | 251.2  |
| steps                   | 203750 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 3400   |
| mean 100 episode reward | 262.9  |
| steps                   | 230242 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 3500   |
| mean 100 episode reward | 270.1  |
| steps                   | 257453 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 3600   |
| mean 100 episode reward | 230.6  |
| steps                   | 280710 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 3700   |
| mean 100 episode reward | 284.5  |
| steps                   | 309363 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 3800   |
| mean 100 episode reward | 186.0  |
| steps                   | 328166 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 3900   |
| mean 100 episode reward | 303.4  |
| steps                   | 358710 |
------------------------------------
Saving model due to mean reward increase: 282.8999938964844 -> 300.70001220703125
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 4000   |
| mean 100 episode reward | 253.8  |
| steps                   | 384290 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 4100   |
| mean 100 episode reward | 245.3  |
| steps                   | 409021 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 4200   |
| mean 100 episode reward | 236.0  |
| steps                   | 432826 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 4300   |
| mean 100 episode reward | 224.0  |
| steps                   | 455426 |
------------------------------------
------------------------------------
| % time spent exploring  | 2      |
| episodes                | 4400   |
| mean 100 episode reward | 300.4  |
| steps                   | 485662 |
------------------------------------
Saving model due to mean reward increase: 300.70001220703125 -> 305.3999938964844
Restored model with mean reward: 305.3999938964844
------------------Inpute arguments------------------
Namespace(alg='deepq', env='DeepCars-v0', env_type=None, extra_import=None, gamestate=None, network='mlp', num_env=None, num_timesteps=500000.0, play=False, reward_scale=1.0, save_path=None, save_video_interval=0, save_video_length=200, seed=None)
{}
----------------------------------------------------
